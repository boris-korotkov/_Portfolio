{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1637029005997
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import azureml\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Experiment\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.core import Model\n",
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1637029007105
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)\n",
    "\n",
    "# Select the workspace\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')\n",
    "\n",
    "\n",
    "# Create an experiment\n",
    "script_folder = './'\n",
    "exp = Experiment(workspace=ws, name='keras-ml')\n",
    "\n",
    "# Load dataset\n",
    "#dataset = Dataset.get_by_name(ws, 'TrainingSet3K')\n",
    "dataset = Dataset.get_by_name(ws, 'Sample-data')\n",
    "\n",
    "# Set the compute node\n",
    "cluster_name = \"standard-ds11\"\n",
    "compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "\n",
    "# Specify docker image\n",
    "keras_env = Environment.from_conda_specification(name = 'keras-2.3.1', file_path = './conda_dependencies.yml')\n",
    "keras_env.docker.base_image = 'mcr.microsoft.com/azureml/minimal-ubuntu18.04-py37-cpu-inference:latest'\n",
    "\n",
    "# GPU base if GPU compute is used \n",
    "#keras_env.docker.base_image = 'mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.0-cudnn7-ubuntu18.04'\n",
    "\n",
    "docker_config = DockerConfiguration(use_docker=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1637029189122
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Set up and run the experiment\n",
    "args = ['--input-data', dataset.as_named_input('training_data'), # Reference to dataset\n",
    "        '--epoch-size', 100] \n",
    "\n",
    "src = ScriptRunConfig(source_directory=script_folder,\n",
    "                      script='keras_model_training.py',\n",
    "                      arguments=args,\n",
    "                      compute_target=compute_target,\n",
    "                      environment=keras_env)\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "run = exp.submit(src)\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1637029362289
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Register and print model version\n",
    "model = run.register_model(model_name='model-1', model_path='outputs/model')\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "import numpy\n",
    "import re\n",
    "import joblib\n",
    "from nltk.stem import PorterStemmer\n",
    "from azureml.core.model import Model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    global tags\n",
    "    global vectorizer\n",
    "\n",
    "    model_root = Model.get_model_path('model-1')\n",
    "    # load json and create model\n",
    "    json_file = open(os.path.join(model_root, 'model-1.json'), 'r')\n",
    "    model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(model_json)\n",
    "    # load weights into new model\n",
    "    model.load_weights(os.path.join(model_root, \"model-1.h5\"))   \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # load vectorizer\n",
    "    vectorizer_file = os.path.join(model_root, 'feature_vectorizer.joblib')\n",
    "    vectorizer = joblib.load(vectorizer_file)\n",
    "\n",
    "    # load tags\n",
    "    tags_file = os.path.join(model_root, 'tags.joblib')\n",
    "    tags = joblib.load(tags_file)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    retured_prediction={}\n",
    "    logging.info(\"Request received\")\n",
    "    data = json.loads(raw_data)[\"data\"]\n",
    "    preprocessed_data = preprocess_data(data)\n",
    "    result = model.predict(preprocessed_data)\n",
    "    logging.info(\"Request processed\")\n",
    "    \n",
    "    #merge tags with predictions\n",
    "    combined_result=dict(zip(tags, [str(round(i*100,2)) for i in result[0]]))\n",
    "    retured_prediction[\"input_string\"]=data\n",
    "    retured_prediction.update(combined_result)\n",
    "    return json.dumps(retured_prediction)\n",
    "\n",
    "# Called when input data is preprocessed\n",
    "def preprocess_data(received_data):\n",
    "    stemmer = PorterStemmer()\n",
    "    returned_text  = re.sub('[\\(\\*]NA[C]?\\s*[\\)\\(]*C?', r'', received_data, flags = re.M)\n",
    "    returned_text= \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z0-9]\", \" \", returned_text).split()]).lower()\n",
    "    returned_text=stemmer.stem(returned_text)\n",
    "    pred_text=[]\n",
    "    pred_text.append(returned_text)\n",
    "    newX =vectorizer.transform(pred_text).toarray()\n",
    "    return newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1637029486791
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Deploy web service\n",
    "\n",
    "myenv = Environment.from_conda_specification(name=\"myenv\", file_path=\"conda_dependencies.yml\")\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1,\n",
    "                                               auth_enabled=False, # this flag generates API keys to secure access\n",
    "                                               memory_gb=1,\n",
    "                                               tags={'name': 'New WebService', 'framework': 'Keras'},\n",
    "                                               description='Keras MLP on text data')\n",
    "\n",
    "service = Model.deploy(workspace=ws, \n",
    "                           name='keras-service', \n",
    "                           models=[model], \n",
    "                           inference_config=inference_config, \n",
    "                           deployment_config=aciconfig)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1637029487458
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1637029487590
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Test the deployed service\n",
    "import json\n",
    "\n",
    "x_new = 'New Text here'\n",
    "\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data (the web service will also accept the data in binary format)\n",
    "predictions = service.run(input_data = input_json)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
